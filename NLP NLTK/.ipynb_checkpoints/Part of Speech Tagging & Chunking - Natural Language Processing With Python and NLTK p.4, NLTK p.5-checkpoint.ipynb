{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Parts of Speech Tagging\n",
    "        \n",
    "    The goal of a POS tagger is to assign linguistic (mostly grammatical) information to sub-sentential units. Such units are called tokens and, most of the time, correspond to words and symbols.\n",
    "\n",
    "\n",
    "\n",
    "    Chinking:  Removal of something. \n",
    "    \n",
    "    \n",
    "    Named Entity Recognition: Recognizing named entity is a specific kind of chunk extraction that uses entity tags along with chunk tags.\n",
    "        Common entity tags include PERSON, LOCATION and ORGANIZATION. POS tagged sentences are parsed into chunk trees with normal chunking but the trees labels can be entity tags in place of chunk phrase tags. NLTK has already a pre-trained named entity chunker which can be used using ne_chunk() method in the nltk.chunk module. This method chunks a single sentence into a Tree.\n",
    "\n",
    "    CC coordinating conjunction\n",
    "CD cardinal digit\n",
    "DT determiner\n",
    "EX existential there (like: “there is” … think of it like “there exists”)\n",
    "FW foreign word\n",
    "IN preposition/subordinating conjunction\n",
    "JJ adjective ‘big’\n",
    "JJR adjective, comparative ‘bigger’\n",
    "JJS adjective, superlative ‘biggest’\n",
    "LS list marker 1)\n",
    "MD modal could, will\n",
    "NN noun, singular ‘desk’\n",
    "NNS noun plural ‘desks’\n",
    "NNP proper noun, singular ‘Harrison’\n",
    "NNPS proper noun, plural ‘Americans’\n",
    "PDT predeterminer ‘all the kids’\n",
    "POS possessive ending parent‘s\n",
    "PRP personal pronoun I, he, she\n",
    "PRP$ possessive pronoun my, his, hers\n",
    "RB adverb very, silently,\n",
    "RBR adverb, comparative better\n",
    "RBS adverb, superlative best\n",
    "RP particle give up\n",
    "TO to go ‘to‘ the store.\n",
    "UH interjection errrrrrrrm\n",
    "VB verb, base form take\n",
    "VBD verb, past tense took\n",
    "VBG verb, gerund/present participle taking\n",
    "VBN verb, past participle taken\n",
    "VBP verb, sing. present, non-3d take\n",
    "VBZ verb, 3rd person sing. present takes\n",
    "WDT wh-determiner which\n",
    "WP wh-pronoun who, what\n",
    "WP$ possessive wh-pronoun whose\n",
    "WRB wh-abverb where, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('state_union')\n",
    " \n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "%matplotlib inline\n",
    "\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized:  \n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            #print(tagged)\n",
    "            \n",
    "            #chunkGram = \"\"\" chunk: {<RB.?>*<VB.?>*<NNP>+<NN>? } \"\"\"    # regex \n",
    "            #chunkParser = nltk.RegexpParser(chunkGram)   # parser to read regex\n",
    "            #chunked = chunkParser.parse(tagged)\n",
    "            #chunked.draw()\n",
    "            \n",
    "            #chinkGram = r\"\"\" chunk: {<.*>+}\n",
    "            #                        }<VB.?|IN|DT|TO>+{\"\"\"    # chink out IN|Dt from the chunk\n",
    "            #chinkParser = nltk.RegexpParser(chinkGram)   # parser to read regex\n",
    "            #chinked = chinkParser.parse(tagged)\n",
    "            #chinked.draw()\n",
    "    except Exception as e:\n",
    "        print (str(e))\n",
    "        \n",
    "        \n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/shantanu/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Named entity Recognition\n",
    "#nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "def process_content_NER():\n",
    "    try:\n",
    "        for i in tokenized[5:]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            NER = nltk.ne_chunk(tagged, binary = True)\n",
    "            NER.draw()\n",
    "    except Exception as e:\n",
    "        print (str(e))\n",
    "        \n",
    "process_content_NER()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
