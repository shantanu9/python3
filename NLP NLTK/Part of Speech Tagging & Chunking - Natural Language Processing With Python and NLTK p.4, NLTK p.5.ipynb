{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Parts of Speech Tagging\n",
    "        \n",
    "    The goal of a POS tagger is to assign linguistic (mostly grammatical) information to sub-sentential units. Such units are called tokens and, most of the time, correspond to words and symbols.\n",
    "\n",
    "\n",
    "    CC coordinating conjunction\n",
    "CD cardinal digit\n",
    "DT determiner\n",
    "EX existential there (like: “there is” … think of it like “there exists”)\n",
    "FW foreign word\n",
    "IN preposition/subordinating conjunction\n",
    "JJ adjective ‘big’\n",
    "JJR adjective, comparative ‘bigger’\n",
    "JJS adjective, superlative ‘biggest’\n",
    "LS list marker 1)\n",
    "MD modal could, will\n",
    "NN noun, singular ‘desk’\n",
    "NNS noun plural ‘desks’\n",
    "NNP proper noun, singular ‘Harrison’\n",
    "NNPS proper noun, plural ‘Americans’\n",
    "PDT predeterminer ‘all the kids’\n",
    "POS possessive ending parent‘s\n",
    "PRP personal pronoun I, he, she\n",
    "PRP$ possessive pronoun my, his, hers\n",
    "RB adverb very, silently,\n",
    "RBR adverb, comparative better\n",
    "RBS adverb, superlative best\n",
    "RP particle give up\n",
    "TO to go ‘to‘ the store.\n",
    "UH interjection errrrrrrrm\n",
    "VB verb, base form take\n",
    "VBD verb, past tense took\n",
    "VBG verb, gerund/present participle taking\n",
    "VBN verb, past participle taken\n",
    "VBP verb, sing. present, non-3d take\n",
    "VBZ verb, 3rd person sing. present takes\n",
    "WDT wh-determiner which\n",
    "WP wh-pronoun who, what\n",
    "WP$ possessive wh-pronoun whose\n",
    "WRB wh-abverb where, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('state_union')\n",
    " \n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "%matplotlib inline\n",
    "\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized:  \n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            #print(tagged)\n",
    "            \n",
    "            chunkGram = \"\"\" chunk: {<RB.?>*<VB.?>*<NNP>+<NN>? } \"\"\"    # regex \n",
    "            chunkParser = nltk.RegexpParser(chunkGram)   # parser to read regex\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            chunked.draw()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print (str(e))\n",
    "        \n",
    "        \n",
    "process_content()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
